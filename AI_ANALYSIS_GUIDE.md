# ü§ñ AI-Powered Interview Analysis

This project now includes comprehensive AI-powered interview analysis that replaces the hardcoded reports with real insights generated from actual interview transcripts and audio data.

## üöÄ Features

### Real AI Analysis
- **OpenAI GPT Integration**: Uses GPT-3.5-turbo to analyze interview responses
- **Sentiment Analysis**: Real-time emotion and confidence detection
- **Natural Language Processing**: Advanced text analysis for communication patterns
- **Audio Analysis Enhancement**: Combines voice metrics with transcript analysis

### Comprehensive Scoring
- **Question-by-Question Analysis**: Individual scoring with strengths/improvements
- **Skills Assessment**: Technical, communication, problem-solving, leadership evaluation
- **Speaking Patterns**: WPM, filler words, vocabulary richness, sentence complexity
- **Confidence Tracking**: Time-based confidence scoring throughout interview

### Key Insights
- **AI-Generated Recommendations**: Personalized feedback based on actual responses
- **Real vs Mock Data Detection**: Shows when using real data vs demo mode
- **Regenerate Analysis**: Re-run analysis with different parameters

## üõ†Ô∏è Setup Instructions

### 1. Environment Variables
Create a `.env.local` file in your project root:

```bash
# Required for AI analysis
OPENAI_API_KEY=your_openai_api_key_here

# Optional: For client-side analysis (not recommended for production)
NEXT_PUBLIC_OPENAI_API_KEY=your_openai_api_key_here
```

### 2. API Key Setup
1. Go to [OpenAI API](https://platform.openai.com/api-keys)
2. Create a new API key
3. Add it to your environment variables
4. Ensure you have sufficient API credits

### 3. Dependencies
All required packages are already installed:
- `openai` - OpenAI API client
- `compromise` - Natural language processing
- `sentiment` - Sentiment analysis
- `axios` - HTTP client

## üîß How It Works

### Data Collection
The system automatically captures:
- **Transcripts**: All spoken content from participants
- **Chat Messages**: Text messages and questions
- **Audio Analysis**: Voice metrics from the Python backend
- **Timestamps**: Precise timing for all interactions

### Analysis Pipeline
1. **Data Extraction**: Collects data from LiveKit room and storage
2. **Preprocessing**: Cleans and structures transcript data
3. **AI Analysis**: Sends to OpenAI for comprehensive evaluation
4. **Enhancement**: Combines AI insights with audio metrics
5. **Scoring**: Generates final scores and recommendations

### Real-time vs Post-Interview
- **During Interview**: Basic metrics and audio analysis
- **After Interview**: Full AI-powered analysis and report generation

## üìä Analysis Components

### Question Analysis
```typescript
interface QuestionAnalysis {
  question: string;
  candidateResponse: string;
  score: number;           // 0-100 overall score
  confidence: number;      // Speaking confidence
  clarity: number;         // Communication clarity
  relevance: number;       // Answer relevance
  depth: number;          // Technical depth
  strengths: string[];     // Key strengths identified
  improvements: string[];  // Areas for improvement
}
```

### Skills Assessment
```typescript
interface SkillAssessment {
  skill: string;          // Technical, Communication, etc.
  score: number;          // 0-100 score
  reasoning: string;      // AI explanation
}
```

### Speaking Patterns
```typescript
interface SpeakingPatterns {
  wordsPerMinute: number;
  fillerWords: number;
  vocabularyRichness: number;
  sentenceComplexity: number;
  averagePauseLength: number;
}
```

## üéØ Usage

### Automatic Analysis
The system automatically runs analysis when the InterviewCompletedPage loads:

```typescript
const { analysisResult, isAnalyzing, hasRealData } = useInterviewAnalysis({
  autoAnalyze: true,
  config: {
    positionRole: 'Senior Software Engineer',
    openaiApiKey: process.env.NEXT_PUBLIC_OPENAI_API_KEY
  }
});
```

### Manual Analysis
You can also trigger analysis manually:

```typescript
const { analyzeInterview } = useInterviewAnalysis();

// Trigger analysis
await analyzeInterview();
```

### Data Capture Integration
To capture data during an interview:

```typescript
import { useInterviewDataCapture } from '@/lib/interviewDataCapture';

const { startCapture, addTranscript, addChatMessage } = useInterviewDataCapture();

// Start capturing when interview begins
startCapture('candidate_identity');

// Add transcript data
addTranscript('candidate', 'This is my response...', timestamp);

// Add chat messages
addChatMessage('Tell me about your experience', 'interviewer', timestamp);
```

## üîç Real Data vs Demo Mode

### With Real Data
- Shows "AI-Powered Analysis" badge
- Uses actual transcript and audio data
- Provides personalized insights and recommendations
- Regenerate button available for re-analysis

### Demo Mode
- Shows "Demo Mode" badge
- Uses sample data for demonstration
- Still shows full UI and functionality
- Perfect for testing and development

## üö® Error Handling

The system includes comprehensive fallback mechanisms:

1. **API Failures**: Falls back to client-side analysis
2. **No OpenAI Key**: Uses enhanced mock data
3. **Network Issues**: Graceful degradation with sample data
4. **Invalid Data**: Robust error handling and user feedback

## üîß Customization

### Custom Questions
```typescript
const config = {
  expectedQuestions: [
    "Tell me about your background",
    "What's your experience with React?",
    "How do you handle challenging situations?"
  ]
};
```

### Different Roles
```typescript
const config = {
  positionRole: "Frontend Developer", // or "Data Scientist", "Product Manager", etc.
};
```

### Analysis Parameters
```typescript
const config = {
  candidateIdentity: "john_doe",
  enableRealTimeAnalysis: true,
  openaiApiKey: "your-key-here"
};
```

## üìà Performance

- **Analysis Time**: 10-30 seconds depending on transcript length
- **API Costs**: ~$0.01-0.05 per analysis (depending on transcript length)
- **Caching**: Results stored in session storage for immediate access
- **Offline Mode**: Falls back to enhanced pattern analysis

## üîê Security

- **Server-side Analysis**: API keys kept secure on server
- **Data Privacy**: Interview data stored locally, not sent to external services
- **Encrypted Storage**: Session storage with cleanup after use
- **Rate Limiting**: Built-in protection against API abuse

## üöÄ Future Enhancements

- **Voice Emotion Analysis**: Real-time emotion detection from audio
- **Facial Expression Analysis**: Computer vision for non-verbal cues
- **Industry-Specific Models**: Specialized analysis for different roles
- **Multi-language Support**: Analysis in multiple languages
- **Real-time Coaching**: Live feedback during interviews

## üêõ Troubleshooting

### Common Issues

1. **"Demo Mode" Always Showing**
   - Check if transcript data is being captured
   - Verify LiveKit integration is working
   - Check browser console for errors

2. **Analysis Fails**
   - Verify OpenAI API key is valid
   - Check API quotas and billing
   - Ensure network connectivity

3. **Slow Analysis**
   - Large transcripts take longer to process
   - Consider chunking very long interviews
   - Monitor OpenAI API response times

### Debug Mode
Enable debug logging:
```typescript
const { analysisResult, error } = useInterviewAnalysis({
  config: { debug: true }
});
```

---

The AI-powered analysis transforms static interview reports into dynamic, personalized insights that provide real value to both interviewers and candidates. The system is designed to be robust, secure, and easy to integrate with existing interview workflows.
